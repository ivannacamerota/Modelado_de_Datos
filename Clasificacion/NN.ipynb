{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2024\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Redes Neuronales para Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las redes neuronales para clasificación toman como salida valores discretos, generalmente valores binarios (0, 1)\n",
    "- El principal cambio que debemos hacer para clasificación es cambiar la salida de la red neuronal. Se le pone una función de activación no lineal a la salida, generalmente se usa la función Sigmoidal. \n",
    "- Como función de costo se usa el Cross Entropy en lugar de la Suma de Residuales\n",
    "- Si tenemos una salida multiclase, se debe usar la función Softmax en lugar de la sigmoidal\n",
    "\n",
    "**Entonces... ¿qué pasaría si tengo una red neuronal con sólo una capa, donde la función de activación es sigmoidal? sería lo mismo que aplicar una regresión logística**\n",
    "\n",
    "Red neuronal con una capa con función de activación sigmoidal = Regresión logística\n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://deeplearningmath.org/images/shallow_NN.png\" width=\"450px\" height=\"280px\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funciones de activación**\n",
    "\n",
    "El comportamiento de las neuronas de las redes neuronales es basado en la función en la que la neurona se especializó. Una neurona puede cambiar su respuesta dependiendo de la función de activación $\\varphi(*)$ que sea seleccionada\n",
    "\n",
    "Funciones comunes:\n",
    "1. Lineal: $\\varphi(\\nu)=\\nu$\n",
    "2. Sigmoidal: $\\varphi(\\nu)=\\frac{e^{\\nu}}{1+e^{\\nu}}$ \n",
    "3. Tanh: $\\varphi(\\nu)=\\frac{e^{\\nu}-e^{-\\nu}}{e^{\\nu}+e^{-\\nu}}=tanh(\\nu)$\n",
    "4. Softplus: $\\varphi(\\nu)=log(1+e^{\\nu})$\n",
    "5. RELU: $\\varphi(\\nu)=max(0,\\nu)$\n",
    "\n",
    "Las funciones de activación suelen ser diferenciables, lo que significa que la derivada de primer orden se puede calcular para un valor de entrada dado. Esto es necesario dado que las redes neuronales generalmente se entrenan utilizando el algoritmo de backpropagation que requiere la derivada del error de predicción para actualizar los pesos del modelo.\n",
    "\n",
    "**¿Cómo elegir la función de activación para las capas ocultas?**\n",
    " \n",
    "- RELU: es la más utilizada para capas ocultas. Es fácil de calcular, lo que la hace más rápida para entrenar. Es simple de implementar y no es tan susceptible a gradientes que se desvanecen\n",
    "- Leaky RELU: Similar a ReLU, pero permite valores negativos pequeños cuando x≤0, lo que evita que las neuronas queden completamente inactivas.\n",
    "- Evita Sigmoid y Tanh en las capas ocultas\n",
    "\n",
    "**¿Cómo elegir la función de activación para las capas de salida?**\n",
    "\n",
    "- Lineal: Para problemas de regresión donde la salida es un valor continuo.\n",
    "- Sigmoidal: típicamente para problemas de clasificación binaria.\n",
    "- Softmax: Para problemas de clasificación multiclase\n",
    "\n",
    "\n",
    "**¿Cómo son las redes neuronales para Clasificación?**\n",
    "\n",
    "$$\\nu^{1} = w_{0}^{1}+w^{1}$$\n",
    "$$y^{1} = \\varphi(\\nu^{1})$$\n",
    "$$\\nu^{2} = w_{0}^{2}+w^{2}y_{1}$$\n",
    "<font color= #2E9AFE>$$y^{2} = \\varphi(\\nu^{2})$$</font>\n",
    "\n",
    "La única diferencia es la última salida. La función de la salida tiene que ser **sigmoidal o softmax**\n",
    "\n",
    "\n",
    "**¿Cómo elegir cuántas capas ocultas?**\n",
    "\n",
    "- Problemas sencillos: Una sola capa oculta suele ser suficiente para capturar patrones simples.\n",
    "- Problemas más complejos (con relaciones no lineales más complicadas): Dos capas ocultas pueden ser útiles \n",
    "\n",
    "En la práctica, la mayoría de los problemas sencillos no necesitan más de 1 o 2 capas ocultas.\n",
    "\n",
    "**¿Cómo elegir cuántas neuronas en las capas ocultas?**\n",
    "\n",
    "- Un buen punto de partida es comenzar con un número de neuronas que sea similar o cercano al número de características de entrada.\n",
    "- Para problemas simples, se puedes comenzar con entre 4 y 16 neuronas por capa.\n",
    "- Si los datos tienen una cantidad moderada de complejidad o son no lineales, podrías aumentar a 32 o 64 neuronas en la capa oculta.\n",
    "- Evita tener muchas más neuronas que características de entrada, ya que eso puede llevar a un sobreajuste.\n",
    "- En redes con múltiples capas ocultas, una estrategia común es que las capas posteriores tengan menos neuronas que las capas iniciales. Esto es porque las primeras capas extraen más características, mientras que las capas más profundas se enfocan en combinarlas.\n",
    "\n",
    "**Backpropagation**\n",
    "\n",
    "Es el método que usa para ajustar el modelo. Minimiza el cross entropy, utilizando el gradiente descendente para calcular los parámetros con el orden del último hacia el primero.\n",
    "\n",
    "**Recomendaciones**\n",
    "\n",
    "- Se recomienda hacer un pre-procesamiento de los datos - Escalamiento\n",
    "- Comúnmente todas las capas ocultas usan la misma función de activación\n",
    "- La función de salida generalmente usa diferente función de activación que el de las capas ocultas. \n",
    "- En la experiencia, conviene más aumentar el número de neuronas ocultas en lugar de aumentar el número de capas ocultas.\n",
    "- Se recomienda no usar muchas capas ocultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo para salida binaria**\n",
    "\n",
    "Queremos predecir si una persona va a tener diabetes o no (Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Librerías\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Librerías\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = data.describe()\n",
    "info = data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cómo se ve la distribución de nuestra variable de salida\n",
    "data['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficando la distribucion de la variable a predecir\n",
    "sns.countplot(x='Outcome', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es un desbalanceo tan severo, por lo tanto no se recomendaría balancear la clase a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data,\n",
    "                  y_vars=['Outcome'],\n",
    "                  x_vars=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar datos para train y test\n",
    "X = data.iloc[:,0:8]\n",
    "Y = np.ravel(data['Outcome'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La red neuronal se beneficia del escalamiento de las variables numéricas (si es necesario)\n",
    "#Escalar datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuántos datos tenemos?\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una recomendación es comenzar con un número de neuronas que sea similar o cercano al número de características de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construir red neuronal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Crear estructura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(8,))) #tenemos 8 variables de entrada\n",
    "model.add(Dense(1, activation='sigmoid')) #La capa de salida debe ser \"sigmoidal\" para problemas binomiales (0 y 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(loss='binary_crossentropy',#función de costo\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento de la red neuronal\n",
    "history = model.fit(X_train, Y_train, epochs=200, validation_data=(X_test, Y_test), verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver el performance del modelo en el entrenamiento (accuracy)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel('Epochs'),plt.ylabel('Accuracy function')\n",
    "plt.title('Accuracy durante el entrenamiento')\n",
    "\n",
    "# Gráfico de la pérdida durante el entrenamiento\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Pérdida en entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida en prueba')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar el modelo para predecir\n",
    "Y_pred = model.predict(X_test) #predecir en términos de decimales o probabilidades \n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\") #en términos de 1 y 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#métricas de performance\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score) #mientras más grandes mejor\n",
    "\n",
    "#métricas en el train\n",
    "accu_train = accuracy_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "prec_train = precision_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "reca_train = recall_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "\n",
    "#métricas en el test\n",
    "accu_test = accuracy_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "prec_test = precision_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "reca_test = recall_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo Multiclase**\n",
    "\n",
    "- Aunque las salidas de la red neuronal están limitadas a un rango de valores entre 0 y 1, no se garantiza que la suma de estos sea igual a 1\n",
    "- Transformar las salidas para que puedan ser usadas como probabilidades ayuda mucho a la interpretabilidad de las predicciones\n",
    "- Transformación Softmax\n",
    "\n",
    "$$\\hat{p}_{l,i}^{*} = \\frac{e^{\\hat{y}_{l,i}}}{\\sum{e^{\\hat{y}_{l,i}}}}$$\n",
    "\n",
    "- $\\hat{y}_{1}=0.25$, $\\hat{y}_{2}=0.76$, $\\hat{y}_{3}=0.1$\n",
    "\n",
    "- $\\hat{p}_{1}=0.3099$, $\\hat{p}_{2}=0.4717$, $\\hat{p}_{3}=0.2184$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "#from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Y #tres tipos de flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribucion de la variable de salida\n",
    "unique_values = np.unique(Y)\n",
    "counts = np.bincount(Y)\n",
    " \n",
    "print(\"Valores:\", unique_values)\n",
    "print(\"Cuenta:\", counts[unique_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la variable target a dummies para poderla trabajar en la red neuronal\n",
    "dummy_y = to_categorical(Y).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en test y train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construcción de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(3, activation='softmax'))#salida\n",
    "\n",
    "#Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, \n",
    "                   epochs=100, \n",
    "                   validation_data=(X_test,y_test), verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver el performance del modelo en el entrenamiento (accuracy)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel('Epochs'),plt.ylabel('Accuracy function')\n",
    "plt.title('Accuracy durante el entrenamiento')\n",
    "\n",
    "#Graficar el categorical crossentropy (loss o funcion de perdida)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot((history.history['loss']), 'r', label='train')\n",
    "ax.plot((history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir con el modelo\n",
    "Y_pred = model.predict(X_test) # en términos de probabilidades\n",
    "Y_prob = np.argmax(Y_pred, axis=1) #en términos de 1 y 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer ingenería en reversa, para dejar las predicciones en el formato original que teníamos de las \"Y\"\n",
    "uniques, ids = np.unique(Y, return_inverse=True)\n",
    "dummy_y = to_categorical(ids, len(uniques))\n",
    "reverse = uniques[dummy_y.argmax(1)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, reverse,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas de performance\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score)\n",
    "\n",
    "#métricas en el train\n",
    "Y_proba= model.predict(X_train)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_train = accuracy_score(y_train, Y_pred)\n",
    "prec_train = precision_score(y_train, Y_pred,average='weighted')\n",
    "reca_train = recall_score(y_train, Y_pred,average='weighted')\n",
    "\n",
    "\n",
    "#métricas en el test\n",
    "Y_proba= model.predict(X_test)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_test = accuracy_score(y_test, Y_pred)\n",
    "prec_test = precision_score(y_test, Y_pred,average='weighted')\n",
    "reca_test = recall_score(y_test, Y_pred,average='weighted')\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
